import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.metrics import davies_bouldin_score, silhouette_score
from datetime import datetime
import plotly.express as px

# Load Datasets
customers = pd.read_csv("Customers.csv")
products = pd.read_csv("Products.csv")
transactions = pd.read_csv("Transactions.csv")

# Convert Dates to Datetime format
customers["SignupDate"] = pd.to_datetime(customers["SignupDate"])
transactions["TransactionDate"] = pd.to_datetime(transactions["TransactionDate"])

# Handling Missing Values
customers.fillna("Unknown", inplace=True)
products.fillna("Unknown", inplace=True)
transactions.fillna(0, inplace=True)

# Merging Data
merged_df = transactions.merge(customers, on="CustomerID").merge(products, on="ProductID")

# Exploratory Data Analysis

# Customer Distribution by Region (1st Business Insight)
plt.figure(figsize=(10, 5))
sns.countplot(x='Region', data=customers)
plt.title("Customer Distribution by Region")
plt.show()

# Total Sales per Product Category (2nd Business Insight)
category_sales = merged_df.groupby("Category")["TotalValue"].sum().reset_index()
sns.barplot(x='Category', y='TotalValue', data=category_sales)
plt.xticks(rotation=45)
plt.title("Total Sales per Product Category")
plt.show()

# Monthly Sales Trend (3rd Business Insight)
merged_df["YearMonth"] = merged_df["TransactionDate"].dt.to_period("M")
monthly_sales = merged_df.groupby("YearMonth")["TotalValue"].sum().reset_index()
plt.figure(figsize=(12, 6))
sns.lineplot(x=monthly_sales["YearMonth"].astype(str), y=monthly_sales["TotalValue"])
plt.xticks(rotation=45)
plt.title("Monthly Sales Trend")
plt.show()

# Customer Signup Trends (4th Business Insight)
signup_trends = customers.groupby(customers["SignupDate"].dt.to_period("M")).size().reset_index(name='Signups')
plt.figure(figsize=(12, 6))
sns.lineplot(x=signup_trends["SignupDate"].astype(str), y=signup_trends["Signups"])
plt.xticks(rotation=45)
plt.title("Customer Signup Trends")
plt.show()

# Customer Purchase Frequency and Recency (5th Business Insight)
# Calculate Recency and Frequency for each customer
today = merged_df["TransactionDate"].max() + pd.Timedelta(days=1)
customer_metrics = merged_df.groupby('CustomerID').agg(
    recency=('TransactionDate', lambda x: (today - x.max()).days),
    frequency=('TransactionID', 'nunique')
).reset_index()

# Plotting Recency vs Frequency
plt.figure(figsize=(12, 6))
sns.scatterplot(x='recency', y='frequency', data=customer_metrics, palette="viridis")
plt.title("Customer Purchase Frequency vs Recency")
plt.xlabel("Recency (Days Since Last Purchase)")
plt.ylabel("Frequency (Number of Purchases)")
plt.show()

# Lookalike Model
def lookalike_model(customers, transactions, top_n=3):
    customer_profiles = transactions.groupby("CustomerID").agg({'TotalValue': 'sum', 'Quantity': 'sum'}).reset_index()
    scaler = StandardScaler()
    scaled_profiles = scaler.fit_transform(customer_profiles.iloc[:, 1:])
    similarity_matrix = cosine_similarity(scaled_profiles)
    
    lookalikes = {}
    for idx, cust_id in enumerate(customer_profiles['CustomerID'][:20]):
        similar_indices = np.argsort(-similarity_matrix[idx])[:top_n+1]
        similar_customers = [(customer_profiles['CustomerID'][i], similarity_matrix[idx][i]) for i in similar_indices if i != idx]
        lookalikes[cust_id] = similar_customers
    
    return lookalikes

lookalike_results = lookalike_model(customers, transactions)
lookalike_df = pd.DataFrame.from_dict(lookalike_results, orient='index')
lookalike_df.to_csv("Lookalike.csv", index=True)

# Clustering (Customer Segmentation)
def customer_segmentation(customers, transactions, n_clusters=4):
    customer_features = transactions.groupby("CustomerID").agg({'TotalValue': 'sum', 'Quantity': 'sum'}).reset_index()
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(customer_features.iloc[:, 1:])
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(scaled_features)
    customer_features['Cluster'] = clusters
    
    db_index = davies_bouldin_score(scaled_features, clusters)
    silhouette_avg = silhouette_score(scaled_features, clusters)
    
    return customer_features, db_index, silhouette_avg

cluster_results, db_index, silhouette_avg = customer_segmentation(customers, transactions)
print("Davies-Bouldin Index:", db_index)
print("Silhouette Score:", silhouette_avg)

# Exporting clustering results
cluster_results.to_csv("Customer_Segmentation.csv", index=False)

# Visualizing Clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x=cluster_results['TotalValue'], y=cluster_results['Quantity'], hue=cluster_results['Cluster'], palette='viridis')
plt.title("Customer Clusters")
plt.xlabel("Total Value")
plt.ylabel("Quantity Purchased")
plt.show()

# Customer Lifetime Value (CLV) Analysis
customer_lifetime_value = merged_df.groupby("CustomerID")["TotalValue"].sum().reset_index()
sns.boxplot(x=customer_lifetime_value["TotalValue"])
plt.title("Customer Lifetime Value Distribution")
plt.show()

# CLV per Region
clv_region = merged_df.groupby("Region")["TotalValue"].sum().reset_index()
sns.barplot(x='Region', y='TotalValue', data=clv_region)
plt.xticks(rotation=45)
plt.title("Customer Lifetime Value by Region")
plt.show()
